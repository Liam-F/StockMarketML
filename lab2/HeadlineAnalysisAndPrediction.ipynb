{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from Database import db\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, concatenate, SpatialDropout1D, GRU\n",
    "from keras.layers import Dense, Flatten, Embedding, LSTM, Activation, BatchNormalization, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Options\n",
    "\n",
    "stocks      = ['AAPL', 'AMD', 'AMZN', 'GOOG', 'MSFT']\n",
    "all_sources = ['reddit', 'reuters', 'twitter', 'seekingalpha', 'fool']\n",
    "\n",
    "max_length  = 50\n",
    "vocab_size  = None # Set by tokenizer\n",
    "emb_size    = 300\n",
    "\n",
    "model_type  = 'regression'\n",
    "\n",
    "epochs      = 180\n",
    "batch_size  = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_headline_to_effect_data():\n",
    "    \"\"\"\n",
    "    Headline -> Effect\n",
    "    \n",
    "    Creates essentially the X, Y data for the embedding model to use\n",
    "    when analyzing/encoding headlines. Returns a list of headlines and\n",
    "    a list of corresponding 'effects' which represent a change in the stock price.\n",
    "    \"\"\"\n",
    "    meta, headlines, effects = [], [], []\n",
    "    \n",
    "    with db() as (conn, cur):\n",
    "        \n",
    "        for stock in stocks:\n",
    "            \n",
    "            print(\"Fetching Stock...\" + stock)\n",
    "            \n",
    "            ## Go through all the headlines ##\n",
    "            \n",
    "            cur.execute(\"SELECT date, source, content FROM headlines WHERE stock=? AND LENGTH(content) >= 16\", [stock])\n",
    "            headline_query = cur.fetchall()\n",
    "            \n",
    "            for (date, source, content) in headline_query:\n",
    "                \n",
    "                event_date = datetime.strptime(date, '%Y-%m-%d') # The date of headline\n",
    "                \n",
    "                add_time = lambda e, days: (e + timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "                \n",
    "                ## Find corresponding tick data ## \n",
    "                \n",
    "                cur.execute(\"\"\"SELECT adjclose FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date\"\"\", \n",
    "                            [stock, \n",
    "                             add_time(event_date, -3), \n",
    "                             add_time(event_date, 0)])\n",
    "                \n",
    "                before_headline_ticks = cur.fetchall()\n",
    "                \n",
    "                cur.execute(\"\"\"SELECT AVG(adjclose) FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date\"\"\", \n",
    "                            [stock, \n",
    "                             add_time(event_date, 1), \n",
    "                             add_time(event_date, 5)])\n",
    "                \n",
    "                after_headline_ticks = cur.fetchall()\n",
    "                \n",
    "                ## Create training example ##\n",
    "                \n",
    "                if len(before_headline_ticks) > 0 and len(after_headline_ticks) > 0 and after_headline_ticks[0][0] != None:\n",
    "                    \n",
    "                    previous_tick = before_headline_ticks[-1][0]\n",
    "                    result_tick = after_headline_ticks[0][0]\n",
    "                    \n",
    "                    if model_type == 'regression':\n",
    "                        \n",
    "                        # Percent Diff (+Normalization Constant)\n",
    "                        effect = [(result_tick - previous_tick) / previous_tick / 0.022]\n",
    "                    \n",
    "                    else:\n",
    "                \n",
    "                        if result_tick > previous_tick:\n",
    "\n",
    "                            effect = [1., 0.]\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            effect = [0., 1.]\n",
    "                        \n",
    "                    meta.append((source, event_date.weekday()))\n",
    "                    headlines.append(content)\n",
    "                    effects.append(effect)\n",
    "                    \n",
    "    return meta, headlines, np.array(effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def encode_sentences(meta, sentences, tokenizer=None, max_length=100, vocab_size=100):\n",
    "    \"\"\"\n",
    "    Encoder\n",
    "    \n",
    "    Takes a list of headlines and converts them into vectors\n",
    "    \"\"\"\n",
    "    ## Encoding Sentences\n",
    "    \n",
    "    if not tokenizer:\n",
    "        \n",
    "        tokenizer = Tokenizer(num_words=vocab_size, filters='', lower=False) # Already Preprocessed\n",
    "    \n",
    "        tokenizer.fit_on_texts(sentences)\n",
    "    \n",
    "    encoded_headlines = tokenizer.texts_to_sequences(sentences)\n",
    "    \n",
    "    padded_headlines = pad_sequences(encoded_headlines, maxlen=max_length, padding='post')\n",
    "    \n",
    "    ## Encoding Meta Data\n",
    "    \n",
    "    # OneHot(Source [reddit/twitter/reuters etc..]) + OneHot(WeekDay)\n",
    "    \n",
    "    meta_matrix = np.zeros((len(sentences), len(all_sources) + 7))\n",
    "    index = 0\n",
    "    \n",
    "    for (source, weekday) in meta:\n",
    "        \n",
    "        meta_matrix[index, all_sources.index(source)] = 1\n",
    "        meta_matrix[index, len(all_sources) + weekday] = 1\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    return meta_matrix, padded_headlines, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_data(X, X2, Y, ratio):\n",
    "    \"\"\"\n",
    "    Splits X/Y to Train/Test\n",
    "    \"\"\"\n",
    "    indexes = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indexes)\n",
    "    \n",
    "    X  = X[indexes]\n",
    "    X2 = X2[indexes]\n",
    "    Y  = Y[indexes]\n",
    "    \n",
    "    train_size = int(len(X) * ratio)\n",
    "    \n",
    "    trainX,  testX  = X[:train_size],  X[train_size:]\n",
    "    trainX2, testX2 = X2[:train_size], X2[train_size:]\n",
    "    trainY,  testY  = Y[:train_size],  Y[train_size:]\n",
    "    \n",
    "    return trainX, trainX2, trainY, testX, testX2, testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embedding_matrix(tokenizer, pretrained_file='glove.840B.300d.txt', purge=False):\n",
    "    \"\"\"Load Vectors from Glove File\"\"\"\n",
    "    print(\"Loading WordVecs..\")\n",
    "    \n",
    "    ## Load Glove File (Super Slow) ##\n",
    "    \n",
    "    glove_db = dict()\n",
    "    \n",
    "    with open(os.path.join('..', 'data', pretrained_file), 'r', encoding=\"utf-8\") as glove:\n",
    "\n",
    "        for line in glove:\n",
    "\n",
    "            values = line.split(' ')\n",
    "            word = values[0].replace('-', '').lower()\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            glove_db[word] = coefs\n",
    "\n",
    "    print('Loaded Word Vectors...' + str(len(glove_db)))\n",
    "    \n",
    "    ## Set Embeddings ##\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_size + 1, emb_size))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        \n",
    "        embedding_vector = glove_db.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "        elif purge:\n",
    "            \n",
    "            with db() as (conn, cur):\n",
    "                \n",
    "                cur.execute(\"SELECT 1 FROM specialwords WHERE word=?\", [word])\n",
    "                \n",
    "                if len(cur.fetchall()) == 0:\n",
    "                    \n",
    "                    print(\"Purge...\" + word)\n",
    "\n",
    "                    cur.execute(\"DELETE FROM headlines WHERE content LIKE ?\", [\"%\" + word + \"%\"])\n",
    "                    conn.commit()\n",
    "            \n",
    "    return embedding_matrix, glove_db\n",
    "\n",
    "def correct_sign_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Accuracy of Being Positive or Negative\n",
    "    \"\"\"\n",
    "    diff = K.equal(y_true > 0, y_pred > 0)\n",
    "    \n",
    "    return K.mean(diff, axis=-1)\n",
    "\n",
    "def get_model(emb_matrix):\n",
    "    \n",
    "    ## Headline ##\n",
    "    \n",
    "    headline_input = Input(shape=(max_length,))\n",
    "    \n",
    "    emb = Embedding(vocab_size + 1, emb_size, input_length=max_length, weights=[emb_matrix], trainable=True)(headline_input)\n",
    "    emb = SpatialDropout1D(.2)(emb)\n",
    "    \n",
    "    # conv = Conv1D(filters=64, kernel_size=5, padding='same', activation='selu')(emb)\n",
    "    # conv = MaxPooling1D(pool_size=3)(conv)\n",
    "    \n",
    "    text_rnn = LSTM(200, dropout=0.3, recurrent_dropout=0.3, return_sequences=False)(emb)\n",
    "    text_rnn = Activation('selu')(text_rnn)\n",
    "    text_rnn = BatchNormalization()(text_rnn)\n",
    "    \n",
    "    # text_rnn = LSTM(300, dropout=0.3, recurrent_dropout=0.3)(text_rnn)\n",
    "    # text_rnn = Activation('relu')(text_rnn)\n",
    "    # text_rnn = BatchNormalization()(text_rnn)\n",
    "    \n",
    "    ## Source ##\n",
    "    \n",
    "    meta_input = Input(shape=(len(all_sources) + 7,))\n",
    "    \n",
    "    ## Combined ##\n",
    "    \n",
    "    merged = concatenate([text_rnn, meta_input])\n",
    "    \n",
    "    final_dense = Dense(100)(merged)\n",
    "    final_dense = Activation('selu')(final_dense)\n",
    "    final_dense = BatchNormalization()(final_dense)\n",
    "    final_dense = Dropout(0.5)(final_dense)\n",
    "    \n",
    "    final_dense = Dense(100)(merged)\n",
    "    final_dense = Activation('selu')(final_dense)\n",
    "    final_dense = BatchNormalization()(final_dense)\n",
    "    final_dense = Dropout(0.5)(final_dense)\n",
    "    \n",
    "    if model_type == 'regression':\n",
    "        \n",
    "        pred_dense = Dense(1)(final_dense)\n",
    "        out = pred_dense\n",
    "        \n",
    "        model = Model(inputs=[headline_input, meta_input], outputs=out)\n",
    "    \n",
    "        model.compile(optimizer=RMSprop(lr=0.001), loss='mse', metrics=[correct_sign_acc])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        pred_dense = Dense(2)(final_dense)\n",
    "        out = Activation('softmax')(pred_dense)\n",
    "        \n",
    "        model = Model(inputs=[headline_input, meta_input], outputs=out)\n",
    "    \n",
    "        model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Stock...AAPL\n",
      "Fetching Stock...AMD\n",
      "Fetching Stock...AMZN\n",
      "Fetching Stock...GOOG\n",
      "Fetching Stock...MSFT\n",
      "Found Words...11541\n",
      "Loading...WordVecs\n",
      "Loaded Word Vectors...1634534\n",
      "(13259, 50) (13259, 12) (3315, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    meta, headlines, effects = make_headline_to_effect_data()\n",
    "    \n",
    "    encoded_meta, encoded_headlines, toke = encode_sentences(meta, \n",
    "                                                             headlines, \n",
    "                                                             max_length=max_length, \n",
    "                                                             vocab_size=vocab_size)\n",
    "    \n",
    "    vocab_size = len(toke.word_counts)\n",
    "    print(\"Found Words......\" + str(vocab_size))\n",
    "    \n",
    "    emb_matrix, glove_db = get_embedding_matrix(toke)\n",
    "    \n",
    "    trainX, trainX2, trainY, testX, testX2, testY = split_data(encoded_headlines, encoded_meta, effects, .8)\n",
    "    \n",
    "    print(trainX.shape, trainX2.shape, testY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-929727e5abb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                         callbacks=[e_stopping, checkpoint, tensorboard])\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m## Display Train History ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Shriv\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Shriv\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1076\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1079\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Shriv\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_begin\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[0;32m     93\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.95\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Shriv\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   4100\u001b[0m     \"\"\"\n\u001b[0;32m   4101\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 4102\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   4103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4104\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Shriv\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   4014\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4016\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4017\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Shriv\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   4133\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4134\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4135\u001b[1;33m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Shriv\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    \n",
    "    ## Save Tokenizer ##\n",
    "    \n",
    "    with open(os.path.join('..', 'models', 'toke.pkl'), 'wb') as toke_file:\n",
    "        pickle.dump(toke, toke_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    ## Create Model ##\n",
    "    \n",
    "    model = get_model(emb_matrix)\n",
    "    \n",
    "    if model_type == 'regression':\n",
    "        monitor_mode = 'correct_sign_acc'\n",
    "    else:\n",
    "        monitor_mode = 'val_acc'\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(datetime.now().strftime(\"%Y,%m,%d-%H,%M,%S,\" + model_type)))\n",
    "    e_stopping = EarlyStopping(monitor=monitor_mode, patience=80)\n",
    "    checkpoint = ModelCheckpoint(os.path.join('..', 'models', 'media-headlines-' + model_type + '.h5'), \n",
    "                                 monitor=monitor_mode,\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True)\n",
    "    \n",
    "    ## Train ##\n",
    "    \n",
    "    history = model.fit([trainX, trainX2],\n",
    "                        trainY,\n",
    "                        epochs=epochs, \n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=([testX, testX2], testY),\n",
    "                        verbose=0,\n",
    "                        callbacks=[e_stopping, checkpoint, tensorboard])\n",
    "    \n",
    "    ## Display Train History ##\n",
    "    \n",
    "    plt.plot(np.log(history.history['loss']))\n",
    "    plt.plot(np.log(history.history['val_loss']))\n",
    "    plt.legend(['LogTrainLoss', 'LogTestLoss'])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history[monitor_mode])\n",
    "    plt.plot(history.history['val_' + monitor_mode])\n",
    "    plt.legend(['TrainAcc', 'TestAcc'])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: ['**COMPANY**s spaceship is going to be harder to get a tour of than area', 'amazon stock climbed percent giving the company a market value of billion and topping microsofts mar', 'new **COMPANY** webpage touts apps amp technology for augmented reality on **PRODUCT**', 'heads of us law amp spy agencies say phones by **COMPANY** rival huawei pose inherent national security risk', 'qualcomm unveils gigabit lte modem amid rumors **COMPANY**s **PRODUCT** going intelonly', 'have a mac test our our mac beta because macs arent immune to malware', 'rearfacing d sensing technology possibly slated for fall **PRODUCT** allowing **COMPANY** to press ar advantage', 'if you launch something thats really different people are either going to say thats amazing or laugh in your f', '**COMPANY** expected to ship m lcd **PRODUCT** units priced at in late', 'went to **COMPANY** park and photographed it with an **PRODUCT** x of course', '**COMPANY** in talks for first order from chinese chipmaker nikkei', 'japan display books fourth straight quarterly loss no partner yet', 'japan display books th straight quarterly loss no partner yet', 'japan display reports th straight quarterly loss', 'warren buffetts berkshirehathaway increases **COMPANY** stake by percent now its largest holding', 'bill gates cautions **COMPANY** and other tech companies about arrogance inviting government interference', 'appaloosa more than triples share stake in **COMPANY**', 'went to **COMPANY** park and photographed it with an **PRODUCT** of course', 'companies set to lose from **COMPANY**s **PRODUCT**s', 'heres why i dont buy this **COMPANY** **PRODUCT** rumor', '**COMPANY** incs awkward d touch situation']\n",
      "Predicting Change Coef: 1.02\n",
      "Predicting Price: 171.14\n",
      "Actual Stock: 167.37\n",
      "Actual Stock Change: 5.62\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ## Load Model For Manual Testing ##\n",
    "    \n",
    "    import keras.metrics\n",
    "    keras.metrics.correct_sign_acc = correct_sign_acc\n",
    "    \n",
    "    with open(os.path.join('..', 'models', 'toke.pkl'), 'rb') as toke_file:\n",
    "        toke = pickle.load(toke_file)\n",
    "    \n",
    "    model = load_model(os.path.join('..', 'models', 'media-headlines-' + model_type + '.h5'))\n",
    "    \n",
    "    ## **This Test May Overlap w/Train Data** ##\n",
    "    \n",
    "    current_date = '2018-02-14'\n",
    "    predict_date = '2018-02-15'\n",
    "    stock = 'AAPL'\n",
    "    \n",
    "    with db() as (conn, cur):\n",
    "        \n",
    "        ## Select Actual Stock Values ##\n",
    "        \n",
    "        cur.execute(\"\"\"SELECT adjclose FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date\"\"\", \n",
    "                    [stock, current_date, predict_date])\n",
    "        ticks = cur.fetchall()\n",
    "        \n",
    "        ## Find Headlines ##\n",
    "    \n",
    "        cur.execute(\"SELECT date, source, content FROM headlines WHERE date=? AND stock=?\", [current_date, stock])\n",
    "        headlines = cur.fetchall()\n",
    "        \n",
    "        ## Process ##\n",
    "        \n",
    "        meta, test_sents = [], []\n",
    "        \n",
    "        for (date, source, content) in headlines:\n",
    "            \n",
    "            meta.append([source, datetime.strptime(date, '%Y-%m-%d').weekday()])\n",
    "            test_sents.append(content)\n",
    "            \n",
    "        encoded_meta, test_encoded, _ = encode_sentences(meta, \n",
    "                                                         test_sents, \n",
    "                                                         tokenizer=toke, \n",
    "                                                         max_length=max_length,\n",
    "                                                         vocab_size=vocab_size)\n",
    "        \n",
    "        predictions = model.predict([test_encoded, encoded_meta])\n",
    "        \n",
    "        ## Display ##\n",
    "        \n",
    "        parse = lambda num: str(round(num, 2))\n",
    "        \n",
    "        print(\"Using: \" + str(test_sents))\n",
    "        \n",
    "        if model_type == 'regression':\n",
    "            \n",
    "            print(\"Predicting Change Coef: \" +  parse(np.mean(predictions[:, 0])))\n",
    "            print(\"Predicting Price: \" +  parse(np.mean(predictions[:, 0]) * .022 * ticks[0][0] + ticks[0][0]))\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            print(\"Predicting Change Coef: \" +  parse(np.mean(predictions[:, 0]) - .5))\n",
    "        \n",
    "        print(\"Actual Stock: \" + parse(ticks[0][0]))\n",
    "        print(\"Actual Stock Change: \" + parse(ticks[-1][0] - ticks[0][0]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEWCAYAAAC0Q+rDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2981982cc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEWCAYAAAA6maO/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTjRQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29b89a57908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST MODEL\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "     \n",
    "    ## Load Model For Manual Testing ##\n",
    "    \n",
    "    import keras.metrics\n",
    "    keras.metrics.correct_sign_acc = correct_sign_acc\n",
    "     \n",
    "    with open(os.path.join('..', 'models', 'toke.pkl'), 'rb') as toke_file:\n",
    "        toke = pickle.load(toke_file)\n",
    "    \n",
    "    model = load_model(os.path.join('..', 'models', 'media-headlines-' + model_type + '.h5'))\n",
    "      \n",
    "    ## Fake Unique Test Data ##\n",
    "    \n",
    "    headlines = [\n",
    "        \"**COMPANY** is the best\",\n",
    "        \"companies set to lose from **COMPANY**s **PRODUCT**s\"\n",
    "    ]\n",
    "    \n",
    "    test_sents, meta = [], []\n",
    "    \n",
    "    for headline in headlines:\n",
    "    \n",
    "        for source in all_sources:\n",
    "\n",
    "            for weekday in range(7):\n",
    "            \n",
    "                test_sents.append(headline)\n",
    "                meta.append([source, weekday])\n",
    "    \n",
    "    ## Process ##\n",
    "    \n",
    "    encoded_meta, test_encoded, _ = encode_sentences(meta, \n",
    "                                                     test_sents, \n",
    "                                                     tokenizer=toke, \n",
    "                                                     max_length=max_length, \n",
    "                                                     vocab_size=vocab_size)\n",
    "    \n",
    "    predictions = model.predict([test_encoded, encoded_meta])\n",
    "    \n",
    "    predictions = predictions.reshape((len(headlines), len(all_sources), 7))\n",
    "    \n",
    "    ## Display Predictions ##\n",
    "    \n",
    "    from matplotlib.colors import Normalize\n",
    "    \n",
    "    for i, headline in enumerate(headlines):\n",
    "        \n",
    "        plt.imshow(predictions[i], interpolation='none', cmap='PRGn', norm=Normalize(vmin=-2, vmax=2))\n",
    "        plt.title(headline)\n",
    "        plt.xlabel('Weekday')\n",
    "        plt.ylabel('Source')\n",
    "        plt.xticks(np.arange(7), list('MTWTFSS'))\n",
    "        plt.yticks(np.arange(len(all_sources)), all_sources)\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
