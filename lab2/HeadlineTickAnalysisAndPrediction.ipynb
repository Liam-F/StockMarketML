{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from Database import db\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, concatenate, SpatialDropout1D, GRU\n",
    "from keras.layers import Dense, Flatten, Embedding, LSTM, Activation, BatchNormalization, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Options\n",
    "\n",
    "stocks      = ['AAPL', 'AMD', 'AMZN', 'GOOG', 'MSFT']\n",
    "all_sources = ['reddit', 'reuters', 'twitter', 'seekingalpha', 'fool']\n",
    "\n",
    "tick_window = 15\n",
    "max_length  = 50\n",
    "vocab_size  = None # Set by tokenizer\n",
    "emb_size    = 300\n",
    "\n",
    "model_type  = 'regression'\n",
    "\n",
    "epochs      = 200\n",
    "batch_size  = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_headline_to_effect_data():\n",
    "    \"\"\"\n",
    "    Headline -> Effect\n",
    "    \n",
    "    Creates essentially the X, Y data for the embedding model to use\n",
    "    when analyzing/encoding headlines. Returns a list of headlines and\n",
    "    a list of corresponding 'effects' which represent a change in the stock price.\n",
    "    \"\"\"\n",
    "    meta, headlines, tick_hists, effects = [], [], [], []\n",
    "    \n",
    "    with db() as (conn, cur):\n",
    "        \n",
    "        for stock in stocks:\n",
    "            \n",
    "            print(\"Fetching Stock...\" + stock)\n",
    "            \n",
    "            ## Go through all the headlines ##\n",
    "            \n",
    "            cur.execute(\"SELECT date, source, content, sentimentlabel FROM headlines WHERE stock=? AND LENGTH(content) >= 16\", [stock])\n",
    "            headline_query = cur.fetchall()\n",
    "            \n",
    "            for (date, source, content, label) in headline_query:\n",
    "                \n",
    "                event_date = datetime.strptime(date, '%Y-%m-%d') # The date of headline\n",
    "                \n",
    "                add_time = lambda e, days: (e + timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "                \n",
    "                ## Find corresponding tick data ## \n",
    "                \n",
    "                cur.execute(\"\"\"SELECT open, high, low, adjclose, volume FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date DESC\"\"\", \n",
    "                            [stock, \n",
    "                             add_time(event_date, -10 - tick_window), \n",
    "                             add_time(event_date, 0)])\n",
    "                \n",
    "                before_headline_ticks = cur.fetchall()[:tick_window]\n",
    "                \n",
    "                if len(before_headline_ticks) != tick_window:\n",
    "                    continue\n",
    "                \n",
    "                cur.execute(\"\"\"SELECT AVG(adjclose) FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date\"\"\", \n",
    "                            [stock, \n",
    "                             add_time(event_date, 1), \n",
    "                             add_time(event_date, 4)])\n",
    "                \n",
    "                after_headline_ticks = cur.fetchall()\n",
    "                \n",
    "                ## Create training example ##\n",
    "                \n",
    "                previous_tick = before_headline_ticks[0][3]\n",
    "                result_tick = after_headline_ticks[0][0]\n",
    "                \n",
    "                if previous_tick and result_tick and len(after_headline_ticks) > 0:\n",
    "                    \n",
    "                    tick_hist = np.array(before_headline_ticks)\n",
    "                    tick_hist -= np.mean(tick_hist, axis=0)\n",
    "                    tick_hist /= np.std(tick_hist, axis=0)\n",
    "                    \n",
    "                    if model_type == 'regression':\n",
    "                        \n",
    "                        # Percent Diff (+Normalization Constant)\n",
    "                        effect = [(result_tick - previous_tick) / previous_tick / 0.15]\n",
    "                        \n",
    "                        # Use labels to adjust effect\n",
    "                        if label != -999:\n",
    "                            if np.sign(label) == np.sign(effect[0]):\n",
    "                                effect = [effect[0] * 2]\n",
    "                            else:\n",
    "                                effect = [effect[0] / 4]\n",
    "                    \n",
    "                    else:\n",
    "                \n",
    "                        if result_tick > previous_tick:\n",
    "                            effect = [1., 0.]\n",
    "                        else:\n",
    "                            effect = [0., 1.]\n",
    "                            \n",
    "                        if label != -999:\n",
    "                            if np.sign(label) != np.sign(effect[0]):\n",
    "                                effect = [.5, .5]\n",
    "                        \n",
    "                    meta.append((source, event_date.weekday()))\n",
    "                    headlines.append(content)\n",
    "                    tick_hists.append(tick_hist)\n",
    "                    effects.append(effect)\n",
    "                    \n",
    "    return meta, headlines, np.array(tick_hists), np.array(effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def encode_sentences(meta, sentences, tokenizer=None, max_length=100, vocab_size=100):\n",
    "    \"\"\"\n",
    "    Encoder\n",
    "    \n",
    "    Takes a list of headlines and converts them into vectors\n",
    "    \"\"\"\n",
    "    ## Encoding Sentences\n",
    "    \n",
    "    if not tokenizer:\n",
    "        \n",
    "        tokenizer = Tokenizer(num_words=vocab_size, filters='', lower=False) # Already Preprocessed\n",
    "    \n",
    "        tokenizer.fit_on_texts(sentences)\n",
    "    \n",
    "    encoded_headlines = tokenizer.texts_to_sequences(sentences)\n",
    "    \n",
    "    padded_headlines = pad_sequences(encoded_headlines, maxlen=max_length, padding='post')\n",
    "    \n",
    "    ## Encoding Meta Data\n",
    "    \n",
    "    # OneHot(Source [reddit/twitter/reuters etc..]) + OneHot(WeekDay)\n",
    "    \n",
    "    meta_matrix = np.zeros((len(sentences), len(all_sources) + 7))\n",
    "    index = 0\n",
    "    \n",
    "    for (source, weekday) in meta:\n",
    "        \n",
    "        meta_matrix[index, all_sources.index(source)] = 1\n",
    "        meta_matrix[index, len(all_sources) + weekday] = 1\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    return meta_matrix, padded_headlines, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_data(X, X2, X3, Y, ratio): #TODO Make Better\n",
    "    \"\"\"\n",
    "    Splits X/Y to Train/Test\n",
    "    \"\"\"\n",
    "    indexes = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indexes)\n",
    "    \n",
    "    X  = X[indexes]\n",
    "    X2 = X2[indexes]\n",
    "    X3 = X3[indexes]\n",
    "    Y  = Y[indexes]\n",
    "    \n",
    "    train_size = int(len(X) * ratio)\n",
    "    \n",
    "    trainX,  testX  = X[:train_size],  X[train_size:]\n",
    "    trainX2, testX2 = X2[:train_size], X2[train_size:]\n",
    "    trainX3, testX3 = X3[:train_size], X3[train_size:]\n",
    "    trainY,  testY  = Y[:train_size],  Y[train_size:]\n",
    "    \n",
    "    return trainX, trainX2, trainX3, trainY, testX, testX2, testX3, testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Stock...AAPL\n",
      "Fetching Stock...AMD\n",
      "Fetching Stock...AMZN\n",
      "Fetching Stock...GOOG\n",
      "Fetching Stock...MSFT\n",
      "Found Words......14216\n",
      "Loading WordVecs...\n",
      "Loaded WordVectors...1634534\n",
      "Purge...antiautomation\n",
      "Purge...standat\n",
      "Purge...dsys\n",
      "Purge...userbench\n",
      "Purge...foxconns\n",
      "Purge...raudiophile\n",
      "Purge...rdquarter\n",
      "Purge...artemr\n",
      "Purge...mkbhd\n",
      "Purge...lenovomotorola\n",
      "Purge...tempursealy\n",
      "Purge...msitweets\n",
      "Purge...gamernexus\n",
      "Purge...centralam\n",
      "Purge...farooks\n",
      "Purge...alibabalinked\n",
      "Purge...timcook\n",
      "Purge...nonexpedited\n",
      "Purge...ezviz\n",
      "Purge...rad**PRODUCT**hack\n",
      "Purge...problemsexcellent\n",
      "Purge...releveraging\n",
      "Purge...apupowered\n",
      "Purge...bombedinstantly\n",
      "Purge...oneblueorangeish\n",
      "Purge...laserfocusedon\n",
      "Purge...steamthe\n",
      "Purge...hackedsaid\n",
      "Purge...rtoronto\n",
      "Purge...thecloud\n",
      "Purge...stload\n",
      "Purge...tvos\n",
      "Purge...webwrapper\n",
      "Purge...tencents\n",
      "Purge...xaphandler\n",
      "Purge...emui\n",
      "Purge...nettonetse\n",
      "Purge...gartnerinc\n",
      "Purge...badgesticker\n",
      "Purge...reatailer\n",
      "Purge...efficincy\n",
      "Purge...consciouscapitalism\n",
      "Purge...instantwatcher\n",
      "Purge...**COMPANY**coms\n",
      "Purge...appinstall\n",
      "Purge...crashiversary\n",
      "Purge...jmsilverbrook\n",
      "Purge...gamersnexus\n",
      "Purge...dsensing\n",
      "Purge...fastinggrowing\n",
      "Purge...hexadite\n",
      "Purge...sepmsrp\n",
      "Purge...transtiioning\n",
      "Purge...**COMPANY**ed\n",
      "Purge...**COMPANY**proof\n",
      "Purge...onshored\n",
      "Purge...stopnr**COMPANY**\n",
      "Purge...aetnas\n",
      "Purge...rpcmr\n",
      "Purge...poetrythemed\n",
      "Purge...labers\n",
      "Purge...mesa**COMPANY**gpu\n",
      "Purge...holocube\n",
      "Purge...ibeacons\n",
      "Purge...rebench\n",
      "Purge...pundittracker\n",
      "Purge...**PRODUCT**ogliquid\n",
      "Purge...ry**PRODUCT**\n",
      "Purge...r**PRODUCT**phone\n",
      "Purge...up**COMPANY**\n",
      "Purge...dissppeared\n",
      "Purge...civilizationr\n",
      "Purge...gurud\n",
      "Purge...**PRODUCT**videocom\n",
      "Purge...betterthanfeared\n",
      "Purge...tomshardwares\n",
      "Purge...crucialcom\n",
      "Purge...reacquihires\n",
      "Purge...pipowered\n",
      "Purge...happeninggif\n",
      "Purge...vmwares\n",
      "Purge...pcworldvideos\n",
      "Purge...cashierless\n",
      "Purge...luckynb\n",
      "Purge...facebookesque\n",
      "Purge...sabrepc\n",
      "Purge...**COMPANY**r\n",
      "Purge...ntocsr\n",
      "Purge...futureandrew\n",
      "Purge...setflair\n",
      "Purge...coinstars\n",
      "Purge...**PRODUCT**style\n",
      "Purge...chuxing\n",
      "Purge...automoderator\n",
      "Purge...ztes\n",
      "Purge...r**COMPANY**\n",
      "Purge...themingstock\n",
      "Purge...adduplex\n",
      "Purge...catalystmaker\n",
      "Purge...**MEMBER**s\n",
      "Purge...inrelease\n",
      "Purge...rmad\n",
      "Purge...r**COMPANY**whatshouldibuy\n",
      "Purge...atandts\n",
      "Purge...lazboys\n",
      "Purge...metanautix\n",
      "Purge...uncarrier\n",
      "Purge...**PRODUCT**time\n",
      "Purge...profitkilling\n",
      "Purge...threadripper\n",
      "Purge...billionaireapproved\n",
      "Purge...exnokia\n",
      "Purge...googlehunting\n",
      "Purge...farpassword\n",
      "Purge...leftfordead\n",
      "Purge...outships\n",
      "Purge...nokiapoweruser\n",
      "Purge...samsungsupported\n",
      "Purge...xiaomis\n",
      "Purge...marketfoolery\n",
      "Purge...imininent\n",
      "Purge...photobeamer\n",
      "Purge...backblazes\n",
      "Purge...irgcproduced\n",
      "Purge...yolod\n",
      "Purge...nearmonopolies\n",
      "Purge...alertspopups\n",
      "Purge...rossmanns\n",
      "Purge...monolink\n",
      "Purge...rnintendo\n",
      "Purge...invalidkcrawford\n",
      "Purge...smalltablet\n",
      "Purge...gillianhturner\n",
      "Purge...spywareenab\n",
      "Purge...samsungare\n",
      "Purge...comparisonp\n",
      "Purge...miopenrocm\n",
      "Purge...ruddocks\n",
      "Purge...recordbound\n",
      "Purge...yuphoria\n",
      "Purge...bezelfree\n",
      "Purge...mmsq\n",
      "Purge...wsjs\n",
      "Purge...ipo**PRODUCT**l\n",
      "Purge...buildzoid\n",
      "Purge...unboxingthoughts\n",
      "Purge...wynnwin\n",
      "Purge...a**PRODUCT**d\n",
      "Purge...cpusapus\n",
      "Purge...masterracers\n",
      "Purge...simplygon\n",
      "Purge...iotechfi\n",
      "Purge...rsimracing\n",
      "Purge...neweggca\n",
      "Purge...rstockpicks\n",
      "Purge...pampg\n",
      "Purge...marketsfocused\n",
      "Purge...ydbbaebox\n",
      "Purge...smsmms\n",
      "Purge...moviesshows\n",
      "Purge...pstits\n",
      "Purge...**COMPANY**news\n",
      "Purge...madnight\n",
      "Purge...latestacquisition\n",
      "Purge...ridehailing\n",
      "Purge...sonymicrosoftnintendo\n",
      "Purge...nflsized\n",
      "Purge...ofhimself\n",
      "Purge...polarispowered\n",
      "Purge...**PRODUCT**ith\n",
      "Purge...quadhd\n",
      "Purge...wstudent\n",
      "Purge...toasterrefrigerator\n",
      "Purge...girlswhocode\n",
      "Purge...netbreeze\n",
      "Purge...one**COMPANY**place\n",
      "Purge...gigback\n",
      "Purge...jayztwocents\n",
      "Purge...stockswalmart\n",
      "Purge...to**COMPANY**\n",
      "Purge...r**COMPANY**help\n",
      "Purge...senatorshoshana\n",
      "Purge...eventticketing\n",
      "Purge...dillans\n",
      "Purge...chevesligon\n",
      "Purge...ipo**PRODUCT**\n",
      "Purge...elops\n",
      "Purge...stockgrant\n",
      "Purge...octprints\n",
      "Purge...r**PRODUCT**dev\n",
      "Purge...screenisfine\n",
      "Purge...worldpanels\n",
      "Purge...losseslloyds\n",
      "Purge...siliconlotterycom\n",
      "Purge...unavailabe\n",
      "Purge...**PRODUCT**d\n",
      "Purge...roundspepper\n",
      "Purge...lisasu\n",
      "Purge...alibabas\n",
      "Purge...costcolike\n",
      "Purge...closefar\n",
      "Purge...trebleized\n",
      "Purge...reasonagain\n",
      "Purge...gba**PRODUCT**\n",
      "Purge...**PRODUCT**home\n",
      "Purge...callglobal\n",
      "Purge...un**COMPANY**\n",
      "Purge...transenterix\n",
      "Purge...fordwaymo\n",
      "Purge...raijintek\n",
      "Purge...ltechs\n",
      "Purge...**COMPANY**rtp\n",
      "Purge...sdcardfs\n",
      "Purge...fasterslower\n",
      "Purge...mac**PRODUCT**\n",
      "Purge...dollaragram\n",
      "Purge...psvr\n",
      "Purge...**PRODUCT**fire\n",
      "Purge...cyanx\n",
      "Purge...rpcmasterrace\n",
      "Purge...geekstock\n",
      "Purge...stampscom\n",
      "Purge...msncom\n",
      "Purge...bottomfiring\n",
      "Purge...fnccapslol\n",
      "Purge...jobyinc\n",
      "Purge...rexmormon\n",
      "Purge...weirdcreepy\n",
      "Purge...highestconviction\n",
      "Purge...modacoswitch\n",
      "Purge...**PRODUCT**vsps\n",
      "Purge...polarisbased\n",
      "Purge...eurorally\n",
      "Purge...distur**PRODUCT**\n",
      "Purge...corecivic\n",
      "Purge...**PRODUCT**s**PRODUCT**s\n",
      "Purge...bluetoothmiracast\n",
      "Purge...einhorns\n",
      "Purge...weektomac\n",
      "Purge...watchos\n",
      "Purge...frequenzies\n",
      "Purge...allyoucanread\n",
      "Purge...fbi**COMPANY**\n",
      "Purge...englishindianow\n",
      "Purge...lasership\n",
      "Purge...tomshardwarede\n",
      "Purge...evleaks\n",
      "Purge...redmondmagcom\n",
      "Purge...c**COMPANY**\n",
      "Purge...rvideos\n",
      "Purge...alwaysthats\n",
      "Purge...samsungesque\n",
      "Purge...overclockingguide\n",
      "Purge...**COMPANY**nvdaintc\n",
      "Purge...corporationnokia\n",
      "Purge...spillsevere\n",
      "Purge...pbtech\n",
      "Purge...esapist\n",
      "Purge...realdont\n",
      "Purge...qibased\n",
      "Purge...usersperks\n",
      "Purge...indystarcom\n",
      "Purge...showerthought\n",
      "Purge...pcgaming\n",
      "Purge...linuss\n",
      "Purge...nvidia**COMPANY**\n",
      "Purge...kghz\n",
      "Purge...biasedgoggles\n",
      "Purge...videocardzcom\n",
      "Purge...blumoo\n",
      "Purge...**COMPANY**rs\n",
      "Purge...**COMPANY**gpu**PRODUCT**si\n",
      "Purge...computerbase\n",
      "Purge...gammaxx\n",
      "Purge...canucksreview\n",
      "Purge...rfuryqfa\n",
      "Purge...directcanadacom\n",
      "Purge...dropboxs\n",
      "Purge...dolbys\n",
      "Purge...pickerwhat\n",
      "Purge...bigtech\n",
      "Purge...rgaming\n",
      "Purge...cupertinos\n",
      "Purge...isseems\n",
      "Purge...lineageos\n",
      "Purge...chushou\n",
      "Purge...brotli\n",
      "Purge...computerbasede\n",
      "Purge...rgooglehome\n",
      "Purge...screentobody\n",
      "Purge...oveclockers\n",
      "Purge...cantmiss\n",
      "Purge...manowars\n",
      "Purge...lyfts\n",
      "Purge...hexusnet\n",
      "Purge...samsungsstrategy\n",
      "Purge...**COMPANY**ibm\n",
      "Purge...upgradegate\n",
      "Purge...attachlocation\n",
      "Purge...videocardz\n",
      "Purge...**PRODUCT**r\n",
      "Purge...gncs\n",
      "Purge...httpstcofqvxvwt\n",
      "Purge...amazoncoms\n",
      "Purge...**COMPANY**gpupro\n",
      "Purge...nonrgb\n",
      "Purge...handsetdivision\n",
      "Purge...bedsidebedroom\n",
      "Purge...replacementspare\n",
      "Purge...socialmediarussia\n",
      "Purge...fridaylike\n",
      "Purge...rjavascript\n",
      "Purge...guruds\n",
      "Purge...zyngas\n",
      "Purge...chartsmindblank\n",
      "Purge...ruddockapprice\n",
      "Purge...souqcom\n",
      "Purge...outerwall\n",
      "Purge...benjlin\n",
      "Purge...jcase\n",
      "Purge...phonesxmixradio\n",
      "Purge...ilumi\n",
      "Purge...lvmhs\n",
      "Purge...eufy\n",
      "Purge...ataribox\n",
      "Purge...clim**PRODUCT**\n",
      "Purge...uberflagship\n",
      "Purge...quru\n",
      "Purge...roddenberrys\n",
      "Purge...usersallows\n",
      "Purge...**PRODUCT**before\n",
      "Purge...**COMPANY**samsung\n",
      "Purge...bezeless\n",
      "Purge...slickdealsbrickseek\n",
      "Purge...overthoughtorg\n",
      "Purge...eulcs\n",
      "Purge...**COMPANY**ians\n",
      "Purge...donglegate\n",
      "Purge...muzei\n",
      "Purge...kgtx\n",
      "Purge...itsomething\n",
      "Purge...ownersis\n",
      "Purge...launcher**PRODUCT**\n",
      "Purge...**PRODUCT**smartthingszwave\n",
      "Purge...lowbezel\n",
      "Purge...stillcont\n",
      "Purge...htcusa\n",
      "Purge...iaman\n",
      "Purge...komplettno\n",
      "Purge...readdles\n",
      "Purge...avgmin\n",
      "Purge...iceqx\n",
      "Purge...assistsnt\n",
      "Purge...derauer\n",
      "Purge...iprated\n",
      "Purge...aiasaservice\n",
      "Purge...exchangedeutsche\n",
      "Purge...staplesoffice\n",
      "Purge...raskreddit\n",
      "Purge...palmrejection\n",
      "Purge...concerntrolling\n",
      "Purge...voiceshotword\n",
      "Purge...camelcamelcamel\n",
      "Purge...pathtraced\n",
      "Purge...i**COMPANY**\n",
      "Purge...customstock\n",
      "Purge...xpocalypse\n",
      "Purge...jdcom\n",
      "Purge...heat**PRODUCT**\n",
      "Purge...theenterprisemarket\n",
      "Purge...wchristiansen\n",
      "Purge...winarm\n",
      "Purge...nuverra\n",
      "Purge...connectedcar\n",
      "Purge...**COMPANY**nokia\n",
      "Purge...chromecasts\n",
      "Purge...iiphenom\n",
      "Purge...voxeljet\n",
      "Purge...mindfactoryuk\n",
      "Purge...ambientsense\n",
      "Purge...intel**COMPANY**\n",
      "Purge...edgesqueeze\n",
      "Purge...sengs\n",
      "Purge...burstiner\n",
      "Purge...xivelys\n",
      "Purge...createmoveedit\n",
      "Purge...an**PRODUCT**\n",
      "Purge...officialblockchain\n",
      "Purge...freeeven\n",
      "Purge...transenterixs\n",
      "Purge...cutress\n",
      "Purge...estpm\n",
      "Purge...ruin**COMPANY**s\n",
      "Purge...indeeo\n",
      "Purge...hardwareasaservice\n",
      "Purge...benchmarksin\n",
      "Purge...whatsappmd\n",
      "Purge...seconardy\n",
      "Purge...stud**PRODUCT**\n",
      "Purge...nybasically\n",
      "Purge...flagshipwill\n",
      "Purge...ublock\n",
      "Purge...keyboardtrackpad\n",
      "Purge...dualpersona\n",
      "Purge...stockmindfactory\n",
      "Purge...freesync\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purge...answerdesk**COMPANY**storecom\n",
      "Purge...betterred\n",
      "Purge...broadlink\n",
      "Purge...eltonstoneman\n",
      "Purge...preoder\n",
      "Purge...stocks**COMPANY**\n",
      "Purge...rbestof**PRODUCT**day\n",
      "Purge...hamburgermenu\n",
      "Purge...homepod\n",
      "Purge...compressionfree\n",
      "Purge...harmonixs\n",
      "Purge...whywhy\n",
      "Purge...thurrottcom\n",
      "Purge...digitaltransformation\n",
      "Purge...changelogsplease\n",
      "Purge...aeotec\n",
      "Purge...rhardware\n",
      "Purge...forbescom\n",
      "Purge...rtechnology\n",
      "Purge...ocku\n",
      "Purge...**COMPANY**whole\n",
      "Purge...expansionsource\n",
      "Purge...r**PRODUCT**\n",
      "Purge...grinched\n",
      "Purge...notebookchecknet\n",
      "Purge...backforward\n",
      "Purge...salesforcecom\n",
      "Purge...mojonetworks\n",
      "Purge...dividendpayers\n",
      "Purge...gpedevices\n",
      "Purge...**COMPANY**care\n",
      "Purge...carecom\n",
      "Purge...namesdescriptions\n",
      "Purge...**PRODUCT**fury\n",
      "Purge...farenjoy\n",
      "Purge...keqiangs\n",
      "Purge...rootedunlocked\n",
      "Purge...cpchardware\n",
      "Purge...mcparseface\n",
      "Purge...beatsx\n",
      "Purge...dellemc\n",
      "Purge...jerryrigeverything\n",
      "Purge...**PRODUCT**forgot\n",
      "Purge...anantechs\n",
      "Purge...streethigh\n",
      "Purge...studentyr\n",
      "Purge...ambtitions\n",
      "Purge...vittici\n",
      "Purge...stockpure\n",
      "Purge...nadellas\n",
      "Purge...comscores\n",
      "Purge...hololens\n",
      "Purge...banketchapp\n",
      "Purge...pandg\n",
      "Purge...**COMPANY**usps\n",
      "Purge...invensenses\n",
      "Purge...**PRODUCT**book\n",
      "Purge...autosignature\n",
      "Purge...rentbuy\n",
      "Purge...eiswolf\n",
      "Purge...betterpocketnow\n",
      "Purge...goldenport\n",
      "Purge...oxygenos\n",
      "Purge...samsungbarnes\n",
      "Purge...rnvidia\n",
      "Purge...baconit\n",
      "Purge...kinectless\n",
      "Purge...rxiaomi\n",
      "Purge...dwominecraft\n",
      "Purge...lumentums\n",
      "Purge...smsmart\n",
      "Purge...rlumialovers\n",
      "Purge...phonecases\n",
      "Purge...holdcos\n",
      "Purge...faqssidebar\n",
      "Purge...arkit\n",
      "Purge...**PRODUCT**withaheadphonejack\n",
      "Purge...**PRODUCT**us\n",
      "Purge...accentures\n",
      "Purge...seriesps\n",
      "Purge...specdb\n",
      "Purge...airdisplay\n",
      "Purge...anydo\n",
      "Purge...ndgeneration\n",
      "Purge...cybershopping\n",
      "Purge...cityman\n",
      "Purge...**COMPANY**help\n",
      "Purge...mobilegeddon\n",
      "Purge...bonkershigh\n",
      "Purge...dell**COMPANY**\n",
      "Purge...incs**PRODUCT**\n",
      "Purge...madebygoogle\n",
      "Purge...trippling\n",
      "Purge...ghzghz\n",
      "Purge...yellens\n",
      "Purge...cartlist\n",
      "Purge...huaweibuilt\n",
      "Purge...radioshacks\n",
      "Purge...wileyfox\n",
      "Purge...willstarbucks\n",
      "Purge...**COMPANY**ns\n",
      "Purge...encodingediting\n",
      "Purge...amazonde\n",
      "Purge...zolkorn\n",
      "Purge...nikkeis\n",
      "Purge...**PRODUCT**mac\n",
      "Purge...indaw\n",
      "Purge...myetherwallet\n",
      "Purge...redmi\n",
      "Purge...playstv\n",
      "Purge...rpics\n",
      "Purge...**PRODUCT**ipod\n",
      "Purge...hewlettpackards\n",
      "Purge...priceperf\n",
      "Purge...ph**PRODUCT**\n",
      "Purge...firmwaremobi\n",
      "Purge...csiqueira\n",
      "Purge...saloncom\n",
      "Purge...sandp\n",
      "Purge...sensetv\n",
      "Purge...onleaks\n",
      "Purge...belifore\n",
      "Purge...mkbhds\n",
      "Purge...snapchatsupport\n",
      "Purge...gamespreorders\n",
      "Purge...httpamexcoqgeabc\n",
      "Purge...mercadolibres\n",
      "Purge...r**COMPANY**s\n",
      "Purge...chainfirexda\n",
      "Purge...ibeacon\n",
      "Purge...waymouber\n",
      "Purge...mindblanktech\n",
      "Purge...aheadthis\n",
      "Purge...nolongerupdated\n",
      "Purge...lowpe\n",
      "Purge...mulallys\n",
      "Purge...**COMPANY**cart\n",
      "Purge...oneclip\n",
      "Purge...**PRODUCT**will\n",
      "Purge...sonymicrosoft\n",
      "Purge...swapchat\n",
      "Purge...exynosh\n",
      "Purge...stockdroidscom\n",
      "Purge...focuswalmart\n",
      "Purge...tydlig\n",
      "Purge...desktoplaptop\n",
      "Purge...launchweekend\n",
      "Purge...commentsxpost\n",
      "Purge...independentunknown\n",
      "Purge...reviewtechpowerup\n",
      "Purge...**PRODUCT**onarm\n",
      "Purge...hotchips\n",
      "Purge...specialreport\n",
      "Purge...apkupdater\n",
      "Purge...**COMPANY**intel\n",
      "Purge...fitbits\n",
      "Purge...rhomeautomation\n",
      "Purge...truedepth\n",
      "Purge...comixtroversy\n",
      "Purge...delidding\n",
      "Purge...**PRODUCT**day\n",
      "Purge...unibail\n",
      "Purge...cirps\n",
      "Purge...delidded\n",
      "Purge...hundredpoint\n",
      "Purge...**COMPANY**joe\n",
      "Purge...helpwm\n",
      "Purge...tvcom\n",
      "Purge...ahva\n",
      "Purge...commandquestion\n",
      "Purge...ipa**PRODUCT**screen\n",
      "Purge...overstockcom\n",
      "Purge...detachables\n",
      "Purge...bioterrorismdefense\n",
      "Purge...airspros\n",
      "Purge...subscriberssource\n",
      "Purge...currentc\n",
      "Purge...connecttalk\n",
      "Purge...**COMPANY**giving\n",
      "Purge...**COMPANY**ian\n",
      "Purge...expirerenew\n",
      "Purge...hardwarefr\n",
      "Purge...theoverclocker\n",
      "Purge...**COMPANY**hachette\n",
      "Purge...futuremarks\n",
      "Purge...**COMPANY**fueled\n",
      "Purge...gojek\n",
      "Purge...sharebuyback\n",
      "Purge...**PRODUCT**shine\n",
      "Purge...apple**COMPANY**\n",
      "Purge...phonetracking\n",
      "Purge...leveltechs\n",
      "Purge...chiranjeevis\n",
      "Purge...bakein\n",
      "Purge...wpurchase\n",
      "Purge...gaminggb\n",
      "Purge...imdbs\n",
      "Purge...abbvies\n",
      "Purge...photomath\n",
      "Purge...pushbullet\n",
      "Purge...homepods\n",
      "Purge...**PRODUCT**vega\n",
      "Purge...dariohealth\n",
      "Purge...imclones\n",
      "Purge...joycon\n",
      "Purge...selectchange\n",
      "Purge...motionagain\n",
      "Purge...**COMPANY**vlk\n",
      "Purge...ayymd\n",
      "Purge...fluffdebris\n",
      "Purge...rimgoingtohellforthis\n",
      "Purge...shiftlow\n",
      "Purge...teknikos\n",
      "Purge...dualapp\n",
      "Purge...anymost\n",
      "Purge...prorender\n",
      "Purge...rejecte**PRODUCT**\n",
      "Purge...zenfone\n",
      "Purge...androidheadlinescom\n",
      "Purge...gingerbreadfour\n",
      "Purge...appleibm\n",
      "Purge...exfacebook\n",
      "Purge...mindfactoryde\n",
      "Purge...**COMPANY**berkshirejpmorgan\n",
      "Purge...adoredtv\n",
      "Purge...ncrius\n",
      "Purge...**COMPANY**paypal\n",
      "Purge...mostrevolutionary\n",
      "Purge...fckoff\n",
      "Purge...**PRODUCT**focused\n",
      "Purge...norush\n",
      "Purge...radiofreetom\n",
      "Purge...wakeword\n",
      "Purge...voteadd\n",
      "Purge...likelylink\n",
      "Purge...dowleading\n",
      "Purge...rad**PRODUCT**\n",
      "Purge...exuber\n",
      "Purge...evgas\n",
      "Purge...pinterests\n",
      "Purge...desktopit\n",
      "Purge...autoapps\n",
      "Purge...waymos\n",
      "Purge...ipodbased\n",
      "Purge...homekit\n",
      "Purge...ryonghung\n",
      "Purge...cabablility\n",
      "Purge...itinvestment\n",
      "Purge...lightstv\n",
      "Purge...skankphone\n",
      "Purge...touchbar\n",
      "Purge...**COMPANY**robert\n",
      "Purge...mspu\n",
      "Purge...hardwareschottede\n",
      "Purge...bitschips\n",
      "Purge...factorio\n",
      "Purge...rfuturology\n",
      "Purge...animatedgifs\n",
      "Purge...irisscanning\n",
      "Purge...nokia**COMPANY**\n",
      "Purge...dmverity\n",
      "Purge...xpoint\n",
      "Purge...thgeneration\n",
      "Purge...lcow\n",
      "Purge...**COMPANY**server\n",
      "Purge...rxrx\n",
      "Purge...stockarriving\n",
      "Purge...familyfriends\n",
      "Purge...pccasegear\n",
      "Purge...rgooglepixel\n",
      "Purge...parsey\n",
      "Purge...nratv\n",
      "Purge...**PRODUCT**phone\n",
      "Purge...apkmirrors\n",
      "Purge...mgpu\n",
      "Purge...appsgames\n",
      "Purge...feedbackproviding\n",
      "Purge...mspoweruser\n",
      "Purge...framerateframetime\n",
      "Purge...phonebuff\n",
      "Purge...brickandmortars\n",
      "Purge...againcan\n",
      "Purge...bitium\n",
      "Purge...cardneweggcom\n",
      "Purge...achips\n",
      "Purge...msfto\n",
      "Purge...attcom\n",
      "Purge...**COMPANY**buyingnetflix\n",
      "Purge...jandjs\n",
      "Purge...coscowal\n",
      "Purge...ubreakifix\n",
      "Purge...**PRODUCT**rs\n",
      "Purge...incsipad\n",
      "Purge...taptic\n",
      "Purge...libreboot\n",
      "Purge...thinkinga\n",
      "Purge...padfree\n",
      "Purge...howtomen\n",
      "Purge...voat\n",
      "Purge...lessknow\n",
      "Purge...xgtn\n",
      "Purge...endgaming\n",
      "Purge...tweaktownkitguru\n",
      "Purge...sharerepurchase\n",
      "Purge...budsstyle\n",
      "Purge...phonefree\n",
      "Purge...goodnotes\n",
      "Purge...backplatevrm\n",
      "Purge...nerdtechgasm\n",
      "Purge...**PRODUCT**bit\n",
      "Purge...mrmobile\n",
      "Purge...mircrosft\n",
      "Purge...phoneandroid\n",
      "Purge...lake**PRODUCT**\n",
      "Purge...speedfocused\n",
      "Purge...datafree\n",
      "Purge...etsys\n",
      "Purge...rmemes\n",
      "Purge...**PRODUCT**police\n",
      "Purge...iwatches\n",
      "Purge...nanoshuffle\n",
      "Purge...chicagotribunecom\n",
      "Purge...whatsthemotivebehind**COMPANY**\n",
      "Purge...meeseeks\n",
      "Purge...thgrade\n",
      "Purge...fakespot\n",
      "Purge...battlebox\n",
      "Purge...contentbuying\n",
      "Purge...notchless\n",
      "Purge...comparrision\n",
      "Purge...internalsdesign\n",
      "Purge...httpstcoaikxvexhc\n",
      "Purge...chineseled\n",
      "Purge...perfdollar\n",
      "Purge...mobile**PRODUCT**\n",
      "Purge...usaud\n",
      "Purge...**COMPANY**crippled\n",
      "Purge...nxzts\n",
      "Purge...aheadwhere\n",
      "Purge...exiphone\n",
      "Purge...foods**COMPANY**\n",
      "Purge...gearbatons\n",
      "Purge...**PRODUCT**instinct\n",
      "Purge...microcenters\n",
      "Purge...productred\n",
      "Purge...joebelfiore\n",
      "Purge...cablevisions\n",
      "Purge...**COMPANY**incs\n",
      "Purge...os**PRODUCT**\n",
      "Purge...agesa\n",
      "Purge...prter\n",
      "Purge...**COMPANY**store\n",
      "Purge...europeproof\n",
      "Purge...internetorg\n",
      "Purge...zlink\n",
      "Purge...yollow\n",
      "Purge...mintcom\n",
      "Purge...emotient\n",
      "Purge...earningsfilled\n",
      "Purge...woligrowski\n",
      "Purge...phone**PRODUCT**\n",
      "Purge...fedfueled\n",
      "Purge...gpuopen\n",
      "Purge...nokita\n",
      "Purge...stockafter\n",
      "Purge...jetcom\n",
      "Purge...recognizition\n",
      "Purge...pgcmxgbl\n",
      "Purge...sprinttmobile\n",
      "Purge...portraitmode\n",
      "Purge...carbond\n",
      "Purge...unitedhealths\n",
      "Purge...rfunny\n",
      "Purge...tfadell\n",
      "Purge...devicetargetinginfo\n",
      "Purge...atandtdirectv\n",
      "Purge...httpoem**PRODUCT**phonecom\n",
      "Purge...httpstcocjxerxn\n",
      "Purge...vivebrand\n",
      "Purge...**COMPANY**storecom\n",
      "Purge...http**PRODUCT**\n",
      "Purge...icahns\n",
      "Purge...amcrest\n",
      "Purge...motogs\n",
      "Purge...alibabatalk\n",
      "Purge...fluxlike\n",
      "Purge...subtimings\n",
      "Purge...huaweis\n",
      "Purge...shirriffs\n",
      "Purge...yellowpagescom\n",
      "Purge...no**PRODUCT**\n",
      "Purge...bughelp\n",
      "Purge...wattmanoverdrive\n",
      "Purge...ustwogames\n",
      "Purge...protesthit\n",
      "Purge...csclient\n",
      "Purge...verzo\n",
      "Purge...tmobileatt\n",
      "Purge...rayymd\n",
      "Purge...macorstockcom\n",
      "Purge...post**PRODUCT**\n",
      "Purge...midchat\n",
      "Purge...videostreamer\n",
      "Purge...pcmasterrace\n",
      "Purge...updateie\n",
      "Purge...mostsatisfied\n",
      "Purge...chronowing\n",
      "Purge...androidios\n",
      "Purge...**PRODUCT**ling\n",
      "Purge...uandrewk\n",
      "Purge...byomicrocenter\n",
      "Purge...dtouch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_embedding_matrix(tokenizer, use_glove=True, pretrained_file='glove.840B.300d.txt', purge=False):\n",
    "    \"\"\"Load Vectors from Glove File\"\"\"\n",
    "    print(\"Loading WordVecs...\")\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_size + 1, emb_size))\n",
    "    \n",
    "    if not use_glove:\n",
    "        return embedding_matrix, None\n",
    "    \n",
    "    ## Load Glove File (Super Slow) ##\n",
    "    \n",
    "    glove_db = dict()\n",
    "    \n",
    "    with open(os.path.join('..', 'data', pretrained_file), 'r', encoding=\"utf-8\") as glove:\n",
    "\n",
    "        for line in glove:\n",
    "\n",
    "            values = line.split(' ')\n",
    "            word = values[0].replace('-', '').lower()\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            glove_db[word] = coefs\n",
    "\n",
    "    print('Loaded WordVectors...' + str(len(glove_db)))\n",
    "    \n",
    "    ## Set Embeddings ##\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        \n",
    "        embedding_vector = glove_db.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "        elif purge:\n",
    "            \n",
    "            with db() as (conn, cur):\n",
    "                \n",
    "                cur.execute(\"SELECT 1 FROM dictionary WHERE word=? AND stock=?\", [word, \"none\"])\n",
    "                \n",
    "                if len(cur.fetchall()) == 0:\n",
    "                    \n",
    "                    print(\"Purge...\" + word)\n",
    "\n",
    "                    cur.execute(\"DELETE FROM headlines WHERE content LIKE ?\", [\"%\" + word + \"%\"])\n",
    "                    conn.commit()\n",
    "            \n",
    "    return embedding_matrix, glove_db\n",
    "\n",
    "def correct_sign_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Accuracy of Being Positive or Negative\n",
    "    \"\"\"\n",
    "    diff = K.equal(y_true > 0, y_pred > 0)\n",
    "    \n",
    "    return K.mean(diff, axis=-1)\n",
    "\n",
    "def get_model(emb_matrix):\n",
    "    \n",
    "    ## Headline ##\n",
    "    \n",
    "    headline_input = Input(shape=(max_length,))\n",
    "    \n",
    "    emb = Embedding(vocab_size + 1, emb_size, input_length=max_length, weights=[emb_matrix], trainable=True)(headline_input)\n",
    "    emb = SpatialDropout1D(.2)(emb)\n",
    "    \n",
    "    # conv = Conv1D(filters=64, kernel_size=5, padding='same', activation='selu')(emb)\n",
    "    # conv = MaxPooling1D(pool_size=3)(conv)\n",
    "    \n",
    "    text_rnn = LSTM(200, dropout=0.3, recurrent_dropout=0.3, return_sequences=False)(emb)\n",
    "    text_rnn = Activation('selu')(text_rnn)\n",
    "    text_rnn = BatchNormalization()(text_rnn)\n",
    "    \n",
    "    # text_rnn = LSTM(300, dropout=0.3, recurrent_dropout=0.3)(text_rnn)\n",
    "    # text_rnn = Activation('relu')(text_rnn)\n",
    "    # text_rnn = BatchNormalization()(text_rnn)\n",
    "    \n",
    "    ## Ticks ##\n",
    "    \n",
    "    tick_input = Input(shape=(tick_window, 5))\n",
    "    \n",
    "    tick_rnn = LSTM(200, dropout=0.4, recurrent_dropout=0.4, return_sequences=False)(tick_input)\n",
    "    tick_rnn = Activation('selu')(tick_rnn)\n",
    "    tick_rnn = BatchNormalization()(tick_rnn)\n",
    "    \n",
    "    ## Meta ##\n",
    "    \n",
    "    meta_input = Input(shape=(len(all_sources) + 7,))\n",
    "    \n",
    "    ## Combined ##\n",
    "    \n",
    "    merged = concatenate([text_rnn, tick_rnn, meta_input])\n",
    "    \n",
    "    final_dense = Dense(300)(merged)\n",
    "    final_dense = Activation('selu')(final_dense)\n",
    "    final_dense = BatchNormalization()(final_dense)\n",
    "    final_dense = Dropout(0.5)(final_dense)\n",
    "    \n",
    "    final_dense = Dense(100)(merged)\n",
    "    final_dense = Activation('selu')(final_dense)\n",
    "    final_dense = BatchNormalization()(final_dense)\n",
    "    final_dense = Dropout(0.5)(final_dense)\n",
    "    \n",
    "    if model_type == 'regression':\n",
    "        \n",
    "        pred_dense = Dense(1)(final_dense)\n",
    "        out = pred_dense\n",
    "        \n",
    "        model = Model(inputs=[headline_input, tick_input, meta_input], outputs=out)\n",
    "    \n",
    "        model.compile(optimizer=RMSprop(lr=0.001), loss='mse', metrics=[correct_sign_acc])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        pred_dense = Dense(2)(final_dense)\n",
    "        out = Activation('softmax')(pred_dense)\n",
    "        \n",
    "        model = Model(inputs=[headline_input, tick_input, meta_input], outputs=out)\n",
    "    \n",
    "        model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    meta, headlines, tick_hists, effects = make_headline_to_effect_data()\n",
    "    \n",
    "    encoded_meta, encoded_headlines, toke = encode_sentences(meta, \n",
    "                                                             headlines, \n",
    "                                                             max_length=max_length, \n",
    "                                                             vocab_size=vocab_size)\n",
    "    \n",
    "    vocab_size = len(toke.word_counts)\n",
    "    print(\"Found Words......\" + str(vocab_size))\n",
    "    \n",
    "    emb_matrix, glove_db = get_embedding_matrix(toke)\n",
    "    \n",
    "    trainX, trainX2, trainX3, trainY, testX, testX2, testX3, testY = split_data(encoded_headlines, tick_hists, encoded_meta, effects, .8)\n",
    "    \n",
    "    print(trainX.shape, trainX2.shape, trainX3.shape, testY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    ## Save Tokenizer ##\n",
    "    \n",
    "    with open(os.path.join('..', 'models', 'toke-tick.pkl'), 'wb') as toke_file:\n",
    "        pickle.dump(toke, toke_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    ## Create Model ##\n",
    "    \n",
    "    model = get_model(emb_matrix)\n",
    "    \n",
    "    if model_type == 'regression':\n",
    "        monitor_mode = 'correct_sign_acc'\n",
    "    else:\n",
    "        monitor_mode = 'val_acc'\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(datetime.now().strftime(\"%Y,%m,%d-%H,%M,%S,tick,\" + model_type)))\n",
    "    e_stopping = EarlyStopping(monitor=monitor_mode, patience=50)\n",
    "    checkpoint = ModelCheckpoint(os.path.join('..', 'models', 'media-headlines-ticks-' + model_type + '.h5'), \n",
    "                                 monitor=monitor_mode,\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True)\n",
    "    \n",
    "    ## Train ##\n",
    "    \n",
    "    history = model.fit([trainX, trainX2, trainX3],\n",
    "                        trainY,\n",
    "                        epochs=epochs, \n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=([testX, testX2, testX3], testY),\n",
    "                        verbose=0,\n",
    "                        callbacks=[e_stopping, checkpoint, tensorboard])\n",
    "    \n",
    "    ## Display Train History ##\n",
    "    \n",
    "    plt.plot(np.log(history.history['loss']))\n",
    "    plt.plot(np.log(history.history['val_loss']))\n",
    "    plt.legend(['LogTrainLoss', 'LogTestLoss'])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history[monitor_mode])\n",
    "    plt.plot(history.history['val_' + monitor_mode])\n",
    "    plt.legend(['TrainAcc', 'TestAcc'])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TEST MODEL\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ## Load Model For Manual Testing ##\n",
    "    \n",
    "    import keras.metrics\n",
    "    keras.metrics.correct_sign_acc = correct_sign_acc\n",
    "    \n",
    "    with open(os.path.join('..', 'models', 'toke-tick.pkl'), 'rb') as toke_file:\n",
    "        toke = pickle.load(toke_file)\n",
    "    \n",
    "    model = load_model(os.path.join('..', 'models', 'media-headlines-ticks-' + model_type + '.h5'))\n",
    "    \n",
    "    ## **This Test May Overlap w/Train Data** ##\n",
    "    \n",
    "    pretick_date = '2018-02-21'\n",
    "    current_date = '2018-02-23'\n",
    "    predict_date = '2018-02-24'\n",
    "    stock = 'AMD'\n",
    "    \n",
    "    with db() as (conn, cur):\n",
    "        \n",
    "        ## Select Actual Stock Values ##\n",
    "        \n",
    "        event_date = datetime.strptime(current_date, '%Y-%m-%d')\n",
    "        \n",
    "        add_time = lambda e, days: (e + timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "                \n",
    "        cur.execute(\"\"\"SELECT open, high, low, adjclose, volume FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date DESC\"\"\", \n",
    "                    [stock, \n",
    "                    add_time(event_date, -10 - tick_window), \n",
    "                    add_time(event_date, 0)])\n",
    "                \n",
    "        before_headline_ticks = cur.fetchall()[:tick_window]\n",
    "        \n",
    "        \n",
    "        cur.execute(\"\"\"SELECT adjclose FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date ASC LIMIT 1\"\"\", \n",
    "                    [stock, \n",
    "                    add_time(event_date, 1), \n",
    "                    add_time(event_date, 6)])\n",
    "        \n",
    "        after_headline_ticks = cur.fetchall()\n",
    "        \n",
    "        tick_hist = np.array(before_headline_ticks)\n",
    "        tick_hist -= np.mean(tick_hist, axis=0)\n",
    "        tick_hist /= np.std(tick_hist, axis=0)\n",
    "        \n",
    "        ## Find Headlines ##\n",
    "    \n",
    "        cur.execute(\"SELECT date, source, content FROM headlines WHERE date BETWEEN ? AND ? AND stock=?\", [pretick_date, current_date, stock])\n",
    "        headlines = cur.fetchall()\n",
    "        \n",
    "        ## Process ##\n",
    "        \n",
    "        meta, test_sents = [], []\n",
    "        \n",
    "        for (date, source, content) in headlines:\n",
    "            \n",
    "            meta.append([source, datetime.strptime(date, '%Y-%m-%d').weekday()])\n",
    "            test_sents.append(content)\n",
    "            \n",
    "        encoded_meta, test_encoded, _ = encode_sentences(meta, \n",
    "                                                         test_sents, \n",
    "                                                         tokenizer=toke, \n",
    "                                                         max_length=max_length,\n",
    "                                                         vocab_size=vocab_size)\n",
    "        \n",
    "        tick_hists = np.array([tick_hist] * len(headlines))\n",
    "        \n",
    "        predictions = model.predict([test_encoded, tick_hists, encoded_meta])\n",
    "        \n",
    "        ## Display ##\n",
    "        \n",
    "        predictions = predictions[:, 0]\n",
    "        \n",
    "        actual_current = before_headline_ticks[0][3]\n",
    "        \n",
    "        try:\n",
    "            actual_result = after_headline_ticks[0][0]\n",
    "        except:\n",
    "            actual_result = -1\n",
    "        \n",
    "        parse = lambda num: str(round(num, 2))\n",
    "        \n",
    "        print(\"Using: \" + str(test_sents))\n",
    "        \n",
    "        if model_type == 'regression':\n",
    "            \n",
    "            print(\"Predicting Change Coef: \" +  parse(np.mean(predictions)))\n",
    "            print(\"Predicting Price: \" +  parse(np.mean(predictions) * 0.02 * actual_current + actual_current))\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            print(\"Predicting Change Coef: \" +  parse(np.mean(predictions) - .5))\n",
    "        \n",
    "        print(\"Actual Stock: \" + parse(actual_current) + \" to \" + parse(actual_result))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MODEL\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ## Load Model For Manual Testing ##\n",
    "    \n",
    "    import keras.metrics\n",
    "    keras.metrics.correct_sign_acc = correct_sign_acc\n",
    "    \n",
    "    with open(os.path.join('..', 'models', 'toke-tick.pkl'), 'rb') as toke_file:\n",
    "        toke = pickle.load(toke_file)\n",
    "    \n",
    "    model = load_model(os.path.join('..', 'models', 'media-headlines-ticks-' + model_type + '.h5'))\n",
    "    \n",
    "    ## **This Test May Overlap w/Train Data** ##\n",
    "    \n",
    "    current_date = '2017-11-01'\n",
    "    past_days = 80\n",
    "    predict_days = 110\n",
    "    stock = 'AAPL'\n",
    "    \n",
    "    with db() as (conn, cur):\n",
    "        \n",
    "        add_time = lambda e, days: (e + timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        pivot_date = datetime.strptime(current_date, '%Y-%m-%d')\n",
    "        \n",
    "        cur.execute(\"\"\"SELECT date, adjclose FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date ASC\"\"\", \n",
    "                    [stock, \n",
    "                    add_time(pivot_date, -past_days), \n",
    "                    add_time(pivot_date, predict_days)])\n",
    "        \n",
    "        real_ticks = cur.fetchall()\n",
    "        dates = sorted([ date for date, _ in real_ticks])\n",
    "        real_ticks = { date: close for (date, close) in real_ticks }\n",
    "        fake_ticks = { date: real_ticks[dates[0]] for date in real_ticks }\n",
    "        \n",
    "        print(dates[-predict_days], \"to\", dates[-1])\n",
    "        \n",
    "        for pred_date in dates[-predict_days:]:\n",
    "        \n",
    "            ## Select Actual Stock Values ##\n",
    "\n",
    "            event_date = datetime.strptime(pred_date, '%Y-%m-%d')\n",
    "            \n",
    "            pretick_date = add_time(event_date, -2)\n",
    "\n",
    "            cur.execute(\"\"\"SELECT open, high, low, adjclose, volume FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date DESC\"\"\", \n",
    "                        [stock, \n",
    "                        add_time(event_date, -10 - tick_window), \n",
    "                        add_time(event_date, 0)])\n",
    "\n",
    "            before_headline_ticks = cur.fetchall()[:tick_window]\n",
    "\n",
    "            tick_hist = np.array(before_headline_ticks)\n",
    "            tick_hist -= np.mean(tick_hist, axis=0)\n",
    "            tick_hist /= np.std(tick_hist, axis=0)\n",
    "\n",
    "            ## Find Headlines ##\n",
    "\n",
    "            cur.execute(\"SELECT date, source, content FROM headlines WHERE date BETWEEN ? AND ? AND stock=?\", [pretick_date, event_date, stock])\n",
    "            headlines = cur.fetchall()\n",
    "\n",
    "            ## Process ##\n",
    "\n",
    "            meta, test_sents = [], []\n",
    "\n",
    "            for (date, source, content) in headlines:\n",
    "\n",
    "                meta.append([source, datetime.strptime(date, '%Y-%m-%d').weekday()])\n",
    "                test_sents.append(content)\n",
    "\n",
    "            encoded_meta, test_encoded, _ = encode_sentences(meta, \n",
    "                                                             test_sents, \n",
    "                                                             tokenizer=toke, \n",
    "                                                             max_length=max_length,\n",
    "                                                             vocab_size=vocab_size)\n",
    "\n",
    "            tick_hists = np.array([tick_hist] * len(headlines))\n",
    "\n",
    "            predictions = model.predict([test_encoded, tick_hists, encoded_meta])\n",
    "            \n",
    "            actual_current = before_headline_ticks[0][3]\n",
    "            \n",
    "            pred_price = np.mean(predictions) * 0.015 * actual_current + actual_current\n",
    "            \n",
    "            fake_ticks[pred_date] = pred_price\n",
    "        \n",
    "        plt.plot([real_ticks[date] for date in dates])\n",
    "        plt.plot([fake_ticks[date] for date in dates])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(np.array([fake_ticks[date] for date in dates]) - np.array([real_ticks[date] for date in dates]))\n",
    "        plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # TEST MODEL\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "     \n",
    "#     ## Load Model For Manual Testing ##\n",
    "    \n",
    "#     import keras.metrics\n",
    "#     keras.metrics.correct_sign_acc = correct_sign_acc\n",
    "     \n",
    "#     with open(os.path.join('..', 'models', 'toke-tick.pkl'), 'rb') as toke_file:\n",
    "#         toke = pickle.load(toke_file)\n",
    "    \n",
    "#     model = load_model(os.path.join('..', 'models', 'media-headlines-ticks-' + model_type + '.h5'))\n",
    "      \n",
    "#     ## Fake Unique Test Data ##\n",
    "    \n",
    "#     headlines = [\n",
    "#         \"**COMPANY** gains a ton of stock after creating **PRODUCT**\",\n",
    "#         \"**COMPANY** loses a ton of stock after killing **PRODUCT**\"\n",
    "#     ]\n",
    "    \n",
    "#     test_sents, meta = [], []\n",
    "    \n",
    "#     for headline in headlines:\n",
    "    \n",
    "#         for source in all_sources:\n",
    "\n",
    "#             for weekday in range(7):\n",
    "            \n",
    "#                 test_sents.append(headline)\n",
    "#                 meta.append([source, weekday])\n",
    "    \n",
    "#     ## Process ##\n",
    "    \n",
    "#     encoded_meta, test_encoded, _ = encode_sentences(meta, \n",
    "#                                                      test_sents, \n",
    "#                                                      tokenizer=toke, \n",
    "#                                                      max_length=max_length, \n",
    "#                                                      vocab_size=vocab_size)\n",
    "    \n",
    "#     predictions = model.predict([test_encoded, encoded_meta])\n",
    "    \n",
    "#     predictions = predictions.reshape((len(headlines), len(all_sources), 7))\n",
    "    \n",
    "#     ## Display Predictions ##\n",
    "    \n",
    "#     from matplotlib.colors import Normalize\n",
    "    \n",
    "#     for i, headline in enumerate(headlines):\n",
    "        \n",
    "#         plt.imshow(predictions[i], interpolation='none', cmap='PRGn', norm=Normalize(vmin=-2, vmax=2))\n",
    "#         plt.title(headline)\n",
    "#         plt.xlabel('Weekday')\n",
    "#         plt.ylabel('Source')\n",
    "#         plt.xticks(np.arange(7), list('MTWTFSS'))\n",
    "#         plt.yticks(np.arange(len(all_sources)), all_sources)\n",
    "#         plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
