{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from Database import db\n",
    " \n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, concatenate, SpatialDropout1D, GRU\n",
    "from keras.layers import Dense, Flatten, Embedding, LSTM, Activation, BatchNormalization, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Options\n",
    "\n",
    "stocks      = ['AAPL', 'AMD', 'AMZN', 'GOOG', 'MSFT', 'INTC']\n",
    "all_sources = ['reddit', 'reuters', 'twitter', 'seekingalpha', 'fool', 'wsj', 'thestreet']\n",
    "\n",
    "sample_size = 5\n",
    "tick_window = 30\n",
    "max_length  = 50\n",
    "vocab_size  = None # Set by tokenizer\n",
    "emb_size    = 300\n",
    "\n",
    "epochs      = 120\n",
    "batch_size  = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_time(date, days):\n",
    "    \n",
    "    return (date + timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "\n",
    "def clean(sentence):\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.replace('-', ' ').replace('_', ' ').replace('&', ' ')\n",
    "    sentence = re.sub('\\$?\\d+%?\\w?', 'numbertoken', sentence)\n",
    "    sentence = ''.join(c for c in sentence if c in \"abcdefghijklmnopqrstuvwxyz \")\n",
    "    sentence = re.sub('\\s+', ' ', sentence)\n",
    "    \n",
    "    return sentence.strip()\n",
    "\n",
    "def make_headline_to_effect_data():\n",
    "    \"\"\"\n",
    "    Headline -> Effect\n",
    "    \n",
    "    Creates essentially the X, Y data for the embedding model to use\n",
    "    when analyzing/encoding headlines. Returns a list of headlines and\n",
    "    a list of corresponding 'effects' which represent a change in the stock price.\n",
    "    \"\"\"\n",
    "    headlines, tick_hists, effects = [], [], []\n",
    "    \n",
    "    with db() as (conn, cur):\n",
    "        \n",
    "        for stock in stocks:\n",
    "            \n",
    "            print(\"Fetching Stock...\" + stock)\n",
    "            \n",
    "            ## Headline For Every Date ##\n",
    "            \n",
    "            cur.execute(\"SELECT DISTINCT date FROM headlines WHERE stock=? ORDER BY date ASC LIMIT 1\", [stock])\n",
    "            start_date = cur.fetchall()[0][0]\n",
    "            \n",
    "            cur.execute(\"SELECT DISTINCT date FROM ticks WHERE stock=? AND date >= ? ORDER BY date ASC\", [stock, start_date])\n",
    "            dates = [date[0] for date in cur.fetchall()]\n",
    "            \n",
    "            for date in dates:\n",
    "                \n",
    "                ## Collect Headlines ##\n",
    "                \n",
    "                event_date = datetime.strptime(date, '%Y-%m-%d')\n",
    "                \n",
    "                cur.execute(\"SELECT date, source, rawcontent FROM headlines WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date DESC\", \n",
    "                            [stock, add_time(event_date, -14), date])\n",
    "                headlines = [(date, source, clean(content), (event_date - datetime.strptime(date, '%Y-%m-%d')).days) \n",
    "                                 for (date, source, content) in cur.fetchall() if content]\n",
    "                \n",
    "                if len(headlines) < sample_size:\n",
    "                    continue\n",
    "                    \n",
    "                ## Find corresponding tick data ## \n",
    "                \n",
    "                cur.execute(\"\"\"SELECT open, high, low, adjclose, volume FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date DESC\"\"\", \n",
    "                            [stock, \n",
    "                             add_time(event_date, -30 - tick_window), \n",
    "                             add_time(event_date, 0)])\n",
    "                \n",
    "                before_headline_ticks = cur.fetchall()[:tick_window]\n",
    "                \n",
    "                if len(before_headline_ticks) != tick_window:\n",
    "                    continue\n",
    "                \n",
    "                cur.execute(\"\"\"SELECT AVG(adjclose) FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date\"\"\", \n",
    "                            [stock, \n",
    "                             add_time(event_date, 1), \n",
    "                             add_time(event_date, 4)])\n",
    "                \n",
    "                after_headline_ticks = cur.fetchall()\n",
    "                \n",
    "                previous_tick = before_headline_ticks[0][3]\n",
    "                result_tick = after_headline_ticks[0][0]\n",
    "                \n",
    "                tick_hist = np.array(before_headline_ticks)\n",
    "                tick_hist -= np.mean(tick_hist, axis=0)\n",
    "                tick_hist /= np.std(tick_hist, axis=0)\n",
    "                \n",
    "                ## Create training example ##\n",
    "                \n",
    "                if previous_tick and result_tick and len(after_headline_ticks) > 0:\n",
    "\n",
    "                    probs = [1 / (headline[3] + 1) for headline in headlines]\n",
    "                    probs /= np.sum(probs)\n",
    "                    \n",
    "                    contents = [headline[2] for headline in headlines]\n",
    "\n",
    "                    num_samples = len(contents) // sample_size\n",
    "                    \n",
    "                    effect = [(result_tick - previous_tick) / previous_tick]\n",
    "\n",
    "                    for i in range(num_samples):\n",
    "\n",
    "                        sample = np.random.choice(contents, sample_size, p=probs)\n",
    "\n",
    "                        headlines.append(sample)\n",
    "                        tick_hists.append(tick_hist)\n",
    "                        effects.append(effect)\n",
    "                    \n",
    "    return headlines, np.array(tick_hists), np.array(effects)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
