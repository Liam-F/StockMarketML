{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_tick_data(stocks):\n",
    "    \"\"\"\n",
    "    Tick Data\n",
    "    \n",
    "    This reads the high, lows, closes, etc. from data csv files\n",
    "    \"\"\"\n",
    "    history = {}\n",
    "    \n",
    "    for stock in stocks:\n",
    "        \n",
    "        history[stock] = {}\n",
    "        \n",
    "        with open(os.path.join('..', 'data', stock + '.csv'), 'r') as data:\n",
    "\n",
    "            for line in data:\n",
    "\n",
    "                if len(line) > 6 and \"Date\" not in line and \"null\" not in line:\n",
    "\n",
    "                    items = line.split(\",\")\n",
    "                    \n",
    "                    date = items[0]\n",
    "                    data = np.array(list(map(float, items[1:]))) # 0, 1, 2, 4, 5 -> OPEN HIGH LOW ADJ_CLOSE VOLUME\n",
    "                    \n",
    "                    history[stock][date] = data\n",
    "        \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_headline_data(stocks):\n",
    "    \"\"\"\n",
    "    Headline Data\n",
    "    \n",
    "    This reads the headlines from the headline csv file (created by CollectData)\n",
    "    \"\"\"\n",
    "    history = {}\n",
    "    \n",
    "    with open(os.path.join('..', 'data', \"_\".join(stocks) + '-headlines.csv'), 'r') as data:\n",
    "        \n",
    "        for line in data:\n",
    "\n",
    "            if len(line) > 6:\n",
    "\n",
    "                stock, date, headline = line.split(\",\")\n",
    "                \n",
    "                if not stock in history:\n",
    "                    \n",
    "                    history[stock] = {}\n",
    "                \n",
    "                history[stock][date] = headline.replace('\\n', '')\n",
    "                \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_headline_to_effect_data(tick_data, head_data):\n",
    "    \"\"\"\n",
    "    Headline -> Effect\n",
    "    \n",
    "    Creates essentially the X, Y data for the embedding model to use\n",
    "    when analyzing/encoding headlines. Returns a list of headlines and\n",
    "    a list of corresponding 'effects' which represent a change in the stock price.\n",
    "    \"\"\"\n",
    "    headlines, effects = [], []\n",
    "    \n",
    "    for stock, dates in head_data.items():\n",
    "        \n",
    "        for date, headline in dates.items():\n",
    "            \n",
    "            next_date = datetime.strptime(date, '%Y-%m-%d') + timedelta(days=1)\n",
    "            next_date = next_date.strftime('%Y-%m-%d')\n",
    "            \n",
    "            if date in tick_data[stock] and next_date in tick_data[stock]:\n",
    "                \n",
    "                tick_on = tick_data[stock][date]\n",
    "                tick_after = tick_data[stock][next_date]\n",
    "                \n",
    "                if tick_after[3] < tick_on[3]:\n",
    "                    \n",
    "                    effects.append(-1)\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    effects.append(1)\n",
    "                    \n",
    "                headlines.append(headline)\n",
    "                \n",
    "    return headlines, effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def encode_sentences(sentences, max_length=10):\n",
    "    \"\"\"\n",
    "    Encoder\n",
    "    \n",
    "    Takes a list of headlines and converts them into vectors\n",
    "    \"\"\"\n",
    "    toke = Tokenizer()\n",
    "    \n",
    "    toke.fit_on_texts(sentences)\n",
    "    \n",
    "    vocab_size = len(toke.word_index) + 1\n",
    "    \n",
    "    encoded_headlines = toke.texts_to_sequences(sentences)\n",
    "    \n",
    "    padded_headlines = pad_sequences(encoded_headlines, maxlen=max_length, padding='post')\n",
    "    \n",
    "    return padded_headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  13  28   1  13   8  29  30  31   0]\n",
      " [  4  16  45   3  46  47   2  17  18  48]\n",
      " [  2  49   9  50  19   0   0   0   0   0]\n",
      " [ 55   6   2  20  56   4  57  58   7  12]\n",
      " [  1  59  60   2  61   3   0   0   0   0]\n",
      " [ 62  63   3  21   7   3  21  64   0   0]\n",
      " [ 66   1  67  68  23  69  23  70  71   3]\n",
      " [ 75  76  77  78  10  24   7  79  10  80]\n",
      " [  1  81  82  83  10  84  85  25  12  86]\n",
      " [ 87  88  89  14  90   0   0   0   0   0]\n",
      " [ 92   6   9  93  94  19   5   9  95  96]\n",
      " [ 97  98  99   8 100 101 102   8 103 104]\n",
      " [109 110   1 111 112 113 114   8  26 115]\n",
      " [123 124 125 126   5 127   6  12   7  25]\n",
      " [  1  27 129  10 130 131 132 133 134 135]\n",
      " [ 11 136   1 137 138 139 140   0   0   0]\n",
      " [142 143  22 144 145   5   9   3   7 146]\n",
      " [ 26  15 147   4  16   2  17  18 148   3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    stocks = ['AAPL']\n",
    "    \n",
    "    tick_data = get_tick_data(stocks)\n",
    "    head_data = get_headline_data(stocks)\n",
    "    \n",
    "    headlines, effects = make_headline_to_effect_data(tick_data, head_data)\n",
    "    \n",
    "    encoded_headlines = encode_sentences(headlines)\n",
    "    \n",
    "    print(encoded_headlines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
