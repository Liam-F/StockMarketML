{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing/Misc\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, LSTM, Dropout, Flatten, Conv1D, BatchNormalization, Activation, GlobalMaxPooling1D, MaxPooling1D, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperz\n",
    "\n",
    "epochs           = 500\n",
    "batch_size       = 64\n",
    "\n",
    "window_size      = 60\n",
    "skip_window_size = 5\n",
    "\n",
    "train_split      = .9\n",
    "emb_size         = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "def create_timeframed_alldata_data(stocks, window_size=10, skip_window_size=2):\n",
    "    \"\"\"\n",
    "    Timeframe Alldata\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stocks : list `str`\n",
    "        The names of the stocks to use (pulled by name from data dir)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X, Y : tuple `np.array`\n",
    "        The X and Y data\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for stock in stocks:\n",
    "        \n",
    "        ### Load From File\n",
    "        \n",
    "        raw_data = []\n",
    "        \n",
    "        with open(os.path.join('..', 'data', stock + '.csv'), 'r') as data:\n",
    "\n",
    "            for line in data:\n",
    "\n",
    "                if len(line) > 6 and \"Date\" not in line and \"null\" not in line:\n",
    "\n",
    "                    items = line.split(\",\")\n",
    "                    items = np.array(list(map(float, items[1:])))\n",
    "\n",
    "                    raw_data.append(np.take(items, [0, 1, 2, 4, 5])) # OPEN HIGH LOW ADJ_CLOSE VOLUME\n",
    "        \n",
    "        data = np.array(raw_data)\n",
    "        \n",
    "        ### Process\n",
    "        \n",
    "        for i in range(1, len(data) - window_size - 1):\n",
    "\n",
    "            time_frame = np.copy(data[i: i + window_size + 1])\n",
    "            \n",
    "            trainable_frame = time_frame[:-skip_window_size-1]\n",
    "\n",
    "            target_close = time_frame[-1, 3]\n",
    "            last_close = trainable_frame[-1, 3]\n",
    "\n",
    "            time_frame -= np.mean(trainable_frame, axis=0)\n",
    "            time_frame /= (np.std(trainable_frame, axis=0) + 1e-7)\n",
    "\n",
    "            X.append(trainable_frame)\n",
    "            \n",
    "            if last_close < target_close:\n",
    "                Y.append([1., target_close - last_close])\n",
    "            else:\n",
    "                Y.append([0., target_close - last_close])\n",
    "            \n",
    "    return np.array(X), np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "\n",
    "def split_data(X, Y, ratio=.8, mix=True):\n",
    "    \"\"\"\n",
    "    Splits X/Y to Train/Test\n",
    "    \"\"\"\n",
    "    train_size = int(len(X) * ratio)\n",
    "    \n",
    "    trainX, testX = X[:train_size], X[train_size:]\n",
    "    trainY, testY = Y[:train_size], Y[train_size:]\n",
    "    \n",
    "    if mix:\n",
    "        \n",
    "        trainX, trainY = shuffle(trainX, trainY, random_state=0)\n",
    "    \n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def get_data(stocks):\n",
    "    \n",
    "    X, Y = create_timeframed_alldata_data(stocks, window_size=window_size, skip_window_size=skip_window_size)\n",
    "    \n",
    "    Y[:, 0] /= np.std(Y[:, 0])\n",
    "    \n",
    "    return split_data(X, Y, ratio=train_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "def binacc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Binary Accuracy\n",
    "    \n",
    "    Keras metric to compute the %accuracy given predicted vs actual\n",
    "    \"\"\"\n",
    "    return K.mean(K.equal(y_true[:, 0] >= 0, y_pred[:, 0] >= 0), axis=-1)\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(200, input_shape=(window_size - skip_window_size, emb_size)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(200))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(80))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[binacc])\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11219, 55, 5) (11219, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    trainX, trainY, testX, testY = get_data(['AAPL', 'GOOG'])\n",
    "    \n",
    "    print(trainX.shape, trainY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = get_model()\n",
    "\n",
    "    reduce_LR = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=30, min_lr=1e-6, verbose=0)\n",
    "    e_stopping = EarlyStopping(monitor='val_binacc', patience=50)\n",
    "    checkpoint = ModelCheckpoint(os.path.join('..', 'models', 'trend-pred.h5'), \n",
    "                                 monitor='val_binacc', \n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True)\n",
    "\n",
    "    history = model.fit(trainX, trainY, epochs=epochs, \n",
    "                                        batch_size=batch_size, \n",
    "                                        validation_data=(testX, testY), \n",
    "                                        verbose=0, \n",
    "                                        callbacks=[e_stopping, checkpoint])\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.legend(['TrainLoss', 'TestLoss'])\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['binacc'])\n",
    "    plt.plot(history.history['val_binacc'])\n",
    "    plt.legend(['TrainAcc', 'TestAcc'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
