{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'zipline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3067b3b0dd9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommission\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslippage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'zipline'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime, timedelta\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "from zipline.api import order, order_target, record, symbol\n",
    "from zipline.finance import commission, slippage\n",
    "import zipline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Database\n",
    "\n",
    "@contextmanager\n",
    "def db(db_filename='stock.db'):\n",
    "    \n",
    "    conn = sqlite3.connect(os.path.join('..', 'data', db_filename), detect_types=sqlite3.PARSE_DECLTYPES|sqlite3.PARSE_COLNAMES)\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    yield conn, cur\n",
    "    \n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Slippage Model\n",
    "\n",
    "class TradeNearTheOpenSlippageModel(slippage.SlippageModel):\n",
    "\n",
    "    def __init__(self, deviation=0.001):\n",
    "        \n",
    "        self.deviation = deviation\n",
    "\n",
    "    def process_order(self, data, order):\n",
    "        \n",
    "        rand = min(np.abs(np.random.normal(0, self.deviation)), 1) # Generate a random value thats likely zero (zero=openprice)\n",
    "        \n",
    "        open_price = data.current(symbol(stock), 'open') \n",
    "        close_price = data.current(symbol(stock), 'close') \n",
    "        \n",
    "        new_price = (close_price - open_price) * rand + open_price \n",
    " \n",
    "        return (new_price, order.amount)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !+!+!+!+! PLACE MODEL HERE !+!+!+!+!\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "stocks      = ['AAPL', 'AMD', 'AMZN', 'GOOG', 'MSFT', 'INTC']\n",
    "all_sources = ['reddit', 'reuters', 'twitter', 'seekingalpha', 'fool', 'wsj', 'thestreet']\n",
    "\n",
    "tick_window = 30\n",
    "max_length  = 50\n",
    "vocab_size  = None # Set by tokenizer\n",
    "emb_size    = 300\n",
    "\n",
    "model_type  = 'regression'\n",
    "\n",
    "epochs      = 250\n",
    "batch_size  = 128\n",
    "\n",
    "\n",
    "def correct_sign_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Accuracy of Being Positive or Negative\n",
    "    \"\"\"\n",
    "    diff = K.equal(y_true > 0, y_pred > 0)\n",
    "    \n",
    "    return K.mean(diff, axis=-1)\n",
    "\n",
    "import keras.metrics\n",
    "keras.metrics.correct_sign_acc = correct_sign_acc\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join('..', 'models', 'toke-tick.pkl'), 'rb') as toke_file:\n",
    "    toke = pickle.load(toke_file)\n",
    "    \n",
    "model = load_model(os.path.join('..', 'models', 'media-headlines-ticks-' + model_type + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !+!+!+!+! PLACE MODEL HERE !+!+!+!+!\n",
    "\n",
    "def add_time(date, days):\n",
    "    \n",
    "    return (date + timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "\n",
    "def encode_sentences(meta, sentences, tokenizer=None, max_length=100, vocab_size=100):\n",
    "    \"\"\"\n",
    "    Encoder\n",
    "    \n",
    "    Takes a list of headlines and converts them into vectors\n",
    "    \"\"\"\n",
    "    ## Encoding Sentences\n",
    "    \n",
    "    if not tokenizer:\n",
    "        \n",
    "        tokenizer = Tokenizer(num_words=vocab_size, filters='', lower=False) # Already Preprocessed\n",
    "    \n",
    "        tokenizer.fit_on_texts(sentences)\n",
    "    \n",
    "    encoded_headlines = tokenizer.texts_to_sequences(sentences)\n",
    "    \n",
    "    padded_headlines = pad_sequences(encoded_headlines, maxlen=max_length, padding='post')\n",
    "    \n",
    "    ## Encoding Meta Data\n",
    "    \n",
    "    # OneHot(Source [reddit/twitter/reuters etc..]) + OneHot(WeekDay)\n",
    "    \n",
    "    meta_matrix = np.zeros((len(sentences), len(all_sources) + 7))\n",
    "    index = 0\n",
    "    \n",
    "    for (source, weekday) in meta:\n",
    "        \n",
    "        meta_matrix[index, all_sources.index(source)] = 1\n",
    "        meta_matrix[index, len(all_sources) + weekday] = 1\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    return meta_matrix, padded_headlines, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !+!+!+!+! PLACE MODEL HERE !+!+!+!+!\n",
    "\n",
    "def predict(stock, model=None, toke=None, current_date=None, predict_date=None, look_back=None):\n",
    "    \n",
    "    if not model or not toke:\n",
    "        \n",
    "        with open(os.path.join('..', 'models', 'toke-tick.pkl'), 'rb') as toke_file:\n",
    "            toke = pickle.load(toke_file)\n",
    "    \n",
    "        model = load_model(os.path.join('..', 'models', 'media-headlines-ticks-' + model_type + '.h5'))\n",
    "        \n",
    "    vocab_size = len(toke.word_counts)\n",
    "        \n",
    "    if not current_date:\n",
    "        current_date = datetime.today()\n",
    "        \n",
    "    if not predict_date:\n",
    "        predict_date = current_date + timedelta(days=1)\n",
    "        \n",
    "    if not look_back:\n",
    "        look_back = 3\n",
    "    \n",
    "    pretick_date = add_time(current_date, -look_back)\n",
    "    \n",
    "    with db() as (conn, cur):\n",
    "        \n",
    "        ## Select Actual Stock Values ##\n",
    "                \n",
    "        cur.execute(\"\"\"SELECT open, high, low, adjclose, volume FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date DESC\"\"\", \n",
    "                    [stock, \n",
    "                    add_time(current_date, -30 - tick_window), \n",
    "                    add_time(current_date, 0)])\n",
    "                \n",
    "        before_headline_ticks = cur.fetchall()[:tick_window]\n",
    "        actual_current = before_headline_ticks[0][3]\n",
    "        \n",
    "        cur.execute(\"\"\"SELECT adjclose FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date ASC LIMIT 1\"\"\", \n",
    "                    [stock, \n",
    "                    add_time(predict_date, 1), \n",
    "                    add_time(predict_date, 5)])\n",
    "        \n",
    "        after_headline_ticks = cur.fetchall()\n",
    "        \n",
    "        tick_hist = np.array(before_headline_ticks)\n",
    "        tick_hist -= np.mean(tick_hist, axis=0)\n",
    "        tick_hist /= np.std(tick_hist, axis=0)\n",
    "        \n",
    "        ## Find Headlines ##\n",
    "    \n",
    "        cur.execute(\"SELECT date, source, content FROM headlines WHERE date BETWEEN ? AND ? AND stock=?\", [pretick_date, current_date, stock])\n",
    "        headlines = cur.fetchall()\n",
    "        \n",
    "        ## Process ##\n",
    "        \n",
    "        meta, test_sents = [], []\n",
    "        \n",
    "        for (date, source, content) in headlines:\n",
    "            \n",
    "            meta.append([source, datetime.strptime(date, '%Y-%m-%d').weekday()])\n",
    "            test_sents.append(content)\n",
    "            \n",
    "        encoded_meta, test_encoded, _ = encode_sentences(meta, \n",
    "                                                         test_sents, \n",
    "                                                         tokenizer=toke, \n",
    "                                                         max_length=max_length,\n",
    "                                                         vocab_size=vocab_size)\n",
    "        \n",
    "        tick_hists = np.array([tick_hist] * len(headlines))\n",
    "        \n",
    "        predictions = model.predict([test_encoded, tick_hists, encoded_meta])[:, 0]\n",
    "        \n",
    "        prices = predictions * 0.023 * actual_current + actual_current\n",
    "        \n",
    "        return predictions, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors\n",
    "\n",
    "def predict_perfect(stock, date): # ~Perfect~ Predictor\n",
    "    \n",
    "    with db() as (conn, cur):\n",
    "        \n",
    "        cur.execute(\"SELECT date, adjclose FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date DESC LIMIT 1\", \n",
    "                    [stock, (date + timedelta(days=-5)).strftime('%Y-%m-%d'), (date + timedelta(days=0)).strftime('%Y-%m-%d')])\n",
    "        before = cur.fetchall()[0]\n",
    "        \n",
    "        cur.execute(\"SELECT date, adjclose FROM ticks WHERE stock=? AND date BETWEEN ? AND ? ORDER BY date ASC LIMIT 1\", \n",
    "                    [stock, (date + timedelta(days=1)).strftime('%Y-%m-%d'), (date + timedelta(days=5)).strftime('%Y-%m-%d')])\n",
    "        after = cur.fetchall()[0]\n",
    "        \n",
    "        if after[1] > before[1]:\n",
    "            return 999\n",
    "        else:\n",
    "            return -999\n",
    "        \n",
    "def predict_deep_nn(stock, date):\n",
    "    \n",
    "    preds, prices = predict(stock, model, toke, current_date=date)\n",
    "\n",
    "# predict_deep_nn('AAPL', datetime(2017, 10, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'AMD'\n",
    "\n",
    "def initialize(context):\n",
    "    context.set_commission(commission.PerShare(cost=0, min_trade_cost=1.0))\n",
    "    context.set_slippage(TradeNearTheOpenSlippageModel())\n",
    "    \n",
    "def handle_data(context, data):\n",
    "    \n",
    "    date = data.current(symbol(stock), 'last_traded').to_datetime()\n",
    "    \n",
    "    pred = predict_perfect(stock, date + timedelta(days=0))\n",
    "    \n",
    "    shares = context.portfolio.positions[symbol(stock)].amount\n",
    "    \n",
    "    # print(date, data.current(symbol(stock), 'price'), pred, shares, round(context.portfolio.cash))\n",
    "    \n",
    "    if pred > 0:\n",
    "        max_shares = context.portfolio.cash // data.current(symbol(stock), 'price')\n",
    "        if max_shares > 0:\n",
    "            order(symbol(stock), max_shares)\n",
    "    else:\n",
    "        if shares > 0:\n",
    "            order_target(symbol(stock), 0)\n",
    "        \n",
    "    record(stock=data.current(symbol(stock), 'price'))\n",
    "    record(shares=context.portfolio.positions[symbol(stock)].amount)\n",
    "\n",
    "start = pd.to_datetime('2017-01-01').tz_localize('US/Eastern')\n",
    "end = pd.to_datetime('2018-03-01').tz_localize('US/Eastern')\n",
    "\n",
    "perf = zipline.run_algorithm(start, end, initialize, 100, handle_data=handle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(211)\n",
    "perf.portfolio_value.plot(ax=ax1)\n",
    "ax1.set_ylabel('Portfolio Value')\n",
    "ax2 = plt.subplot(212, sharex=ax1)\n",
    "perf.stock.plot(ax=ax2)\n",
    "ax2.set_ylabel('Stock Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf.columns)\n",
    "perf[['period_open', 'period_close', 'starting_cash', 'ending_cash', 'portfolio_value', 'shares']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
